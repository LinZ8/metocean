{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#done:'51004','51002','51003','51101','51001','51000','51208'\n",
    "#done:'51201','51204','51210','51202','51203','51205','51407','51206'\n",
    "#done:'51wh0','nwwh1','oouh1','mokh1','klih1','kwhh1','iloh1'\n",
    "#51407 and 51wh0 don't have standard meterological data\n",
    "\n",
    "#if the buoy's name has letter, it has to be lower letter.\n",
    "readin = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_data_url = \"http://www.ndbc.noaa.gov/historical_data.shtml\"\n",
    "main_url = \"http://www.ndbc.noaa.gov\"\n",
    "data_folder = \"python_test/metocean_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readin_ndbc_stdmet(name_buoy):\n",
    "    \n",
    "    #save all years' links of the buoy in to 'a_tags'\n",
    "    req_1 = urllib2.urlopen(hist_data_url)\n",
    "    soup_1 = BeautifulSoup(req_1)\n",
    "    a_tags = soup_1.find_all(\"a\",attrs = {'href':re.compile(\".*\"+name_buoy+\n",
    "                                                          \".*stdmet.*\")})    \n",
    "    if len(a_tags) == 0:\n",
    "        print \"there is no historical standard meterological data for %s buoy\"\\\n",
    "               %(name_buoy)\n",
    "        return\n",
    "    print \"number of years of the data for %s buoy is %i\" \\\n",
    "           %(name_buoy, len(a_tags))\n",
    "        \n",
    "    for i in range(len(a_tags)):\n",
    "        \n",
    "        #for each link, open the 2nd page which contains the download link \n",
    "        link = a_tags[i].get('href')\n",
    "        req_2 = urllib2.urlopen(main_url+link)\n",
    "        soup_2 = BeautifulSoup(req_2)\n",
    "        \n",
    "        #locate the download link and open the .txt file into 'data_str'\n",
    "        data_tag = soup_2.find_all(\"a\",attrs = {'href':re.compile(\".*\"+name_buoy\\\n",
    "                                                +\".*txt.*stdmet.*\")})\n",
    "        data_link = data_tag[0].get('href')\n",
    "        req_3 = urllib2.urlopen(main_url+data_link)\n",
    "        data_str = req_3.read()\n",
    "        \n",
    "        #write data into .csv file and save to the existing folder \"data_folder\"\n",
    "        if sys.version_info[0]<3:\n",
    "            from StringIO import StringIO\n",
    "        else:\n",
    "            from io import StringIO\n",
    "        data_csv = StringIO(data_str)\n",
    "        data_df = pd.read_csv(data_csv,delim_whitespace = True)\n",
    "        year = data_df.iat[2,0]\n",
    "        file_path = '/'+data_folder+'/'+name_buoy+'/'+str(year)+'.csv'\n",
    "        directory = os.path.dirname(file_path)       \n",
    "        try:\n",
    "            os.stat(directory)\n",
    "        except:\n",
    "            os.mkdir(directory)            \n",
    "        data_df.to_csv(file_path)\n",
    "        time.sleep(1)\n",
    "    print \"%s buoy is done\" %name_buoy\n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of years of the data for oouh1 buoy is 12\n",
      "oouh1 buoy is done\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(readin)):\n",
    "    readin_ndbc_stdmet(readin[i])\n",
    "    if i in (3,6,9,12,15,18,21):\n",
    "        time.sleep(10)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
